{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField, StringType\nfrom pyspark.sql.functions import explode, col, count, collect_list, array\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.types import StructType, StructField, StringType\nfrom pyspark.sql.functions import lower\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\n\nspark = SparkSession.builder.appName(\"Assignment\").getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"dd21332d-250b-42c8-ae54-d853252d4886","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Read file skill2vec_50K_csv.gz\nfilepath=\"dbfs:/FileStore/tables/\"\nfilename_skills= \"skill2vec_50K.csv.gz\"\n\nnum_cols = 1000  # Set the maximum number of columns (961)\n\n#Dynamically define the Schema\nschema = StructType([StructField(\"JD_id\", StringType(), True)] + [StructField(f\"skill_{i}\", StringType(), True) for i in range(1, num_cols)])\n\n#Read the csv file\n\ndf_skills = spark.read.option(\"header\", False).option(\"sep\", \",\").schema(schema).csv(filepath+filename_skills) \n\n#Convert the long dataframe where each column corresponds to a particular skill to each row corresponding to a skill\n\ndf_skills = df_skills.select(\"JD_id\", explode(array([col(f\"skill_{i}\") for i in range(1, num_cols)])).alias(\"skill\"))\n\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"194f5d38-b7a7-4d9c-a8ad-a66806d2b982","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Read file Technology_Skills\n\nfilename_tech=\"Technology_Skills.txt\"\ndf_tech_skills = spark.read \\\n    .option(\"header\", True) \\\n    .option(\"delimiter\", \"\\t\") \\\n    .option(\"inferSchema\", True) \\\n    .option(\"mode\", \"DROPMALFORMED\") \\\n    .csv(filepath+filename_tech)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ea6a4ffc-14c6-499d-a608-c1dad31cdd81","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Preprocessing of the file skill2vec_50K_csv.gz\n\n#Remove unnecessary rows that are null  \ndf_skills = df_skills.dropna(subset = \"skill\")\n\n#Remove Duplicates\ndf_skills = df_skills.dropDuplicates()\n\n#Remove trailing and leading spaces \n#df_skills=df_skills.select(\"JD_id\").apply(lambda x: x.strip())\n\n#Assign the data types\ndf_skills = df_skills.withColumn('JD_id', df_skills['JD_id'].cast('int'))\ndf_skills = df_skills.withColumn('skill', df_skills['skill'].cast('string'))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4865e0a0-c0ea-4f8e-80cf-51db656b1737","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Preprocessing of the file Technology_Skills\n\n\n#Specify the datatypes\ndf_tech_skills = df_tech_skills.withColumn('O*NET-SOC Code', df_tech_skills['O*NET-SOC Code'].cast('string'))\ndf_tech_skills = df_tech_skills.withColumn('Example', df_tech_skills['Example'].cast('string'))\ndf_tech_skills = df_tech_skills.withColumn('Commodity Code', df_tech_skills['Commodity Code'].cast('int'))\ndf_tech_skills = df_tech_skills.withColumn('Commodity Title', df_tech_skills['Commodity Title'].cast('string'))\ndf_tech_skills = df_tech_skills.withColumn('Hot Technology', df_tech_skills['Hot Technology'].cast('string'))\ndf_tech_skills = df_tech_skills.withColumn('In Demand', df_tech_skills['In Demand'].cast('string'))\n\n#Rename Columns to appropriate names\ndf_tech_skills = df_tech_skills.withColumnRenamed('O*NET-SOC Code','Code')\n#Rename Columns to appropriate names\ndf_tech_skills = df_tech_skills.withColumnRenamed('Example','skill')\n\n#Convert skills column to lower case \ndf_tech_skills=df_tech_skills.withColumn(\"Skill\", lower(col(\"Skill\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"51023a4b-7b82-42cf-81a2-518340c37e51","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Convert Dataframe to view\ndf_skills.createOrReplaceTempView(\"TBL_JD_SKILLS\")\ndf_tech_skills.createOrReplaceTempView(\"TBL_TECH_SKILLS\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"00748c79-a011-46c8-ab7b-e9d0b3f37822","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Q1 Number of job descriptions\njob_description_count = spark.sql(\"SELECT COUNT(DISTINCT JD_ID) AS COUNT FROM TBL_JD_SKILLS \").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"680c2c60-56dd-486d-9869-82f16605e5cc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----+\n|COUNT|\n+-----+\n|50000|\n+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Q2\ntop_skills = spark.sql(\"SELECT SKILL, COUNT(SKILL) AS COUNT FROM TBL_JD_SKILLS GROUP BY SKILL ORDER BY COUNT DESC LIMIT 10 \").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"48739893-f4eb-44b9-bbab-b67e4248a666","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------------------+-----+\n|               SKILL|COUNT|\n+--------------------+-----+\n|                Java| 1911|\n|          Javascript| 1770|\n|               Sales| 1705|\n|Business Development| 1545|\n|    Web Technologies| 1313|\n|Communication Skills| 1305|\n|         development| 1238|\n|           Marketing| 1184|\n|             Finance| 1078|\n|                HTML| 1067|\n+--------------------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Q3\n# Convert Dataframe to table\ndf_skills.createOrReplaceTempView(\"jd_skills\")\n\njdSkill=spark.sql(\"\"\"SELECT count_skill as `num skills`, COUNT(JD_id) as Freq FROM (SELECT count(skill) as count_skill, JD_id FROM jd_skills group by JD_id) group by count_skill order by Freq desc Limit 5 \"\"\").show()\n\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f4ea535a-ab79-47c9-b21c-bde6235cc6fe","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+-----+\n|num skills| Freq|\n+----------+-----+\n|        10|10477|\n|         5| 3432|\n|         6| 3405|\n|         1| 3386|\n|         7| 3345|\n+----------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Q4 Frequencies with which distinct skills are mentioned in JD and top 10 in desc order (Case insesitive)\n\ntop_skills_caseinsensitive  = spark.sql(\"SELECT LOWER(SKILL) as SKILL, COUNT(SKILL) AS COUNT FROM TBL_JD_SKILLS GROUP BY LOWER(SKILL)  ORDER BY COUNT DESC LIMIT 10 \").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"cf8e0fca-0e52-4fdb-ae01-91e229c9d3e7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------------------+-----+\n|               SKILL|COUNT|\n+--------------------+-----+\n|                java| 2759|\n|          javascript| 2738|\n|               sales| 2680|\n|business development| 2108|\n|           marketing| 1809|\n|                 sql| 1564|\n|              jquery| 1547|\n|                html| 1539|\n|communication skills| 1537|\n|                 bpo| 1530|\n+--------------------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Q5\n\nBefore_Join = spark.sql(\"SELECT COUNT(SKILL) as `BEFORE JOIN` FROM TBL_JD_SKILLS\").show()\nAfter_Join = spark.sql(\"SELECT COUNT(*) as `AFTER JOIN` FROM TBL_JD_SKILLS INNER JOIN TBL_TECH_SKILLS on LOWER(TBL_JD_SKILLS.SKILL) = LOWER(TBL_TECH_SKILLS.SKILL)\").show()\n\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"435076bc-3370-4abf-845a-6afd062485fb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+\n|BEFORE JOIN|\n+-----------+\n|     463803|\n+-----------+\n\n+----------+\n|AFTER JOIN|\n+----------+\n|   1101498|\n+----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Q6\nspark.conf.set(\"spark.sql.repl.eagerEval.maxNumChars\", 10000)  # Set a large value\n\ntop_Commodity_title = spark.sql(\"SELECT `COMMODITY TITLE`, COUNT(*) as COUNT FROM TBL_JD_SKILLS INNER JOIN TBL_TECH_SKILLS on LOWER(TBL_JD_SKILLS.SKILL) = LOWER(TBL_TECH_SKILLS.SKILL) GROUP BY `COMMODITY TITLE` ORDER BY COUNT(*) DESC LIMIT 10\").show(truncate=False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6b3e8a26-7980-4d37-b7f4-33fdf71af4b2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------------------------------------------+------+\n|COMMODITY TITLE                                  |COUNT |\n+-------------------------------------------------+------+\n|Object or component oriented development software|324521|\n|Web platform development software                |298754|\n|Operating system software                        |190926|\n|Development environment software                 |53013 |\n|Data base management system software             |44132 |\n|Analytical or scientific software                |33552 |\n|Web page creation and editing software           |31682 |\n|Data base user interface and query software      |29436 |\n|Spreadsheet software                             |18568 |\n|File versioning software                         |13846 |\n+-------------------------------------------------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2ab0af7c-5c44-4481-8ae4-82a55b5f34ee","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Implementation 2-SQL","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
